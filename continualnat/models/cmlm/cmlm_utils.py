from typing import List, Union

import pandas as pd
import torch
from tabulate import tabulate
from transformers import MBartTokenizer, MBartTokenizerFast


def tabulate_mask_predict_steps(token_ids_at_each_step: torch.Tensor,
                                tokenizer: Union[MBartTokenizer, MBartTokenizerFast]) -> List[str]:
    """
    Tabuletes the tokens generated by the mask-predict algorithm such that they can be printed in a prettier way.
    :param token_ids_at_each_step: tensor of generated tokens at each mask-predict step for a batch of sentences to
        translate, its shape is (bsz, length_beam_size, iterations + 1, max_tgt_len).
    :param tokenizer: the tokenizer used in order to remove the pad tokens.
    :return: a list of prettified strings containing the steps performed by mask-predict for each translated sentence.
    """
    tokens_at_each_step = []
    for token_ids_sentence in token_ids_at_each_step:
        tokens_step = []
        for token_ids in token_ids_sentence:
            tokens_sentence = tokenizer.convert_ids_to_tokens(token_ids)
            tokens_sentence_no_pad = [token for token in tokens_sentence if token != tokenizer.pad_token]
            tokens_step.append(tokens_sentence_no_pad)

        tokens_at_each_step.append(tokens_step)

    df_tokens = [pd.DataFrame(tokens_steps) for tokens_steps in tokens_at_each_step]
    df_tokens_tabulate = [tabulate(df_step) for df_step in df_tokens]
    return df_tokens_tabulate
